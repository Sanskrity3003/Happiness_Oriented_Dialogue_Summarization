# Efficiently Fine-Tuned Flan T5 LLM for Happiness-Oriented Dialogue Summarization

📄 **Published:** IEEE Conference Paper, February 2025  
🔗 **DOI / Link:** [View on IEEE Xplore](https://ieeexplore.ieee.org/document/10984314)  
👩‍💻 **Author:** Sanskriti Yadav  
🆔 **ORCID:** 0009-0000-1339-801X

---

## 📌 Abstract

This research focuses on improving the emotional tone of dialogue summarization systems by applying Parameter-Efficient Fine-Tuning (PEFT) techniques to Google's Flan-T5 large language model. The study introduces a happiness-oriented summarization approach, emphasizing therapeutic nuance and emotional independence in generated responses. Our approach significantly improves ROUGE metrics and human evaluation results over traditional zero-shot and few-shot methods.

---

## ✨ Key Contributions

- 🧠 Fine-tuned the **Flan-T5 LLM** using **LoRA (Low-Rank Adaptation)** and **PEFT** techniques for better memory and compute efficiency.
- 💬 Introduced a **custom annotated dataset** based on the *Happiness Unlimited* dialogues focused on mental well-being.
- 📈 Achieved enhanced **ROUGE and BERTScore** metrics as well as improved human-evaluated emotional quality.
- ⚙️ Demonstrated model effectiveness in **emotionally intelligent dialogue summarization**, with reduced computational overhead.

---

## 🔐 Code & Dataset

The source code and dataset are part of a private academic submission and are **not publicly available** at this time due to authorship protection.

If you are a reviewer, collaborator, or research peer and would like access, please feel free to contact me via email.

---

## 📫 Contact

For inquiries: [sensex3003@gmail.com](mailto:sensex3003@gmail.com)
--- 
## 📄 Citation

If you wish to cite this work in your research, please use the following:

```bibtex
@inproceedings{yadav2025flant5happiness,
  title={Efficiently Fine-Tuned Flan T5 LLM for Happiness-Oriented Dialogue Summarization},
  author={Sanskriti Yadav},
  booktitle={2025 IEEE International Conference on Computational Intelligence},
  year={2025},
  publisher={IEEE},
  doi={10.1109/ICE63309.2025.10984314}
}
