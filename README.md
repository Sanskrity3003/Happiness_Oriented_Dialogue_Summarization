# Efficiently Fine-Tuned Flan T5 LLM for Happiness-Oriented Dialogue Summarization

ğŸ“„ **Published:** IEEE Conference Paper, February 2025  
ğŸ”— **DOI / Link:** [View on IEEE Xplore](https://ieeexplore.ieee.org/document/10984314)  
ğŸ‘©â€ğŸ’» **Author:** Sanskriti Yadav  
ğŸ†” **ORCID:** 0009-0000-1339-801X

---

## ğŸ“Œ Abstract

This research focuses on improving the emotional tone of dialogue summarization systems by applying Parameter-Efficient Fine-Tuning (PEFT) techniques to Google's Flan-T5 large language model. The study introduces a happiness-oriented summarization approach, emphasizing therapeutic nuance and emotional independence in generated responses. Our approach significantly improves ROUGE metrics and human evaluation results over traditional zero-shot and few-shot methods.

---

## âœ¨ Key Contributions

- ğŸ§  Fine-tuned the **Flan-T5 LLM** using **LoRA (Low-Rank Adaptation)** and **PEFT** techniques for better memory and compute efficiency.
- ğŸ’¬ Introduced a **custom annotated dataset** based on the *Happiness Unlimited* dialogues focused on mental well-being.
- ğŸ“ˆ Achieved enhanced **ROUGE and BERTScore** metrics as well as improved human-evaluated emotional quality.
- âš™ï¸ Demonstrated model effectiveness in **emotionally intelligent dialogue summarization**, with reduced computational overhead.

---

## ğŸ” Code & Dataset

The source code and dataset are part of a private academic submission and are **not publicly available** at this time due to authorship protection.

If you are a reviewer, collaborator, or research peer and would like access, please feel free to contact me via email.

---

## ğŸ“« Contact

For inquiries: [sensex3003@gmail.com](mailto:sensex3003@gmail.com)
--- 
## ğŸ“„ Citation

If you wish to cite this work in your research, please use the following:

```bibtex
@inproceedings{yadav2025flant5happiness,
  title={Efficiently Fine-Tuned Flan T5 LLM for Happiness-Oriented Dialogue Summarization},
  author={Sanskriti Yadav},
  booktitle={2025 IEEE International Conference on Computational Intelligence},
  year={2025},
  publisher={IEEE},
  doi={10.1109/ICE63309.2025.10984314}
}
